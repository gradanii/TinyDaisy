{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b7528a-ff71-4395-a0a2-9e9b49a67e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0358726f-3907-4d19-9e42-0dd2e1634309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from daisygrad.tensor import DaisyTensor\n",
    "from daisygrad.neural.layers import Linear, LayerNorm, Embedding, Parameter, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4eb00bd8-17bf-4e7b-9a3a-5defc63f0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daisylm.jax_core.tokenizer import BPETokenizer\n",
    "tokenizer = BPETokenizer(vocab_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "408f3523-6d8b-43ae-8ea5-20f353288c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "strings = [\n",
    "    \"The sun is bright.\",\n",
    "    \"Hello world!\",\n",
    "    \"AI is transforming the world.\",\n",
    "    \"Short\"\n",
    "]\n",
    "\n",
    "tok = [tokenizer.encode(s) for s in strings]\n",
    "\n",
    "max_len = max(len(t) for t in tok)\n",
    "padded_tokens = []\n",
    "for token in tok:\n",
    "    padded_tok = jnp.pad(jnp.array(token), pad_width=(0, max_len - len(token)))\n",
    "    padded_tokens.append(padded_tok)\n",
    "    \n",
    "tokarray = jnp.stack(padded_tokens)\n",
    "inputs = tokarray.at[:, :-1].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6d5d4b8a-0016-465f-802e-396cc900af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DaisyConfig:\n",
    "    block_size: int = 512\n",
    "    vocab_size: int = 4096\n",
    "    n_embed = 768\n",
    "    n_head = 12\n",
    "    n_blocks = 12\n",
    "    dropout: float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d3fe932d-9d39-49f2-88f1-d579575ff2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embed:\n",
    "    def __init__(self, key, config):\n",
    "        key, vec_key = random.split(key)\n",
    "        key, pos_key = random.split(key)\n",
    "        scale = 1 / jnp.sqrt(config.vocab_size)\n",
    "        self.vec_matrix = Embedding(vec_key, config.vocab_size, config.n_embed)\n",
    "        self.pos_matrix = Parameter(random.normal(pos_key, shape=(config.block_size, config.n_embed)) * scale)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        vec_embed = self.vec_matrix(inputs)\n",
    "        indices = jnp.arange(inputs.shape[-1])\n",
    "        pos_embed = self.pos_matrix.take(indices)\n",
    "        return vec_embed + pos_embed\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.vec_matrix.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5f727ad3-9a94-44d0-bedb-42bf5b58ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(42)\n",
    "key, embed_key = random.split(key)\n",
    "config = DaisyConfig()\n",
    "embedding = Embed(embed_key, config)\n",
    "x = embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6500f07f-701d-4c95-9e24-372bd38e178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 28, 768)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "890d96f0-30d4-4ce8-8755-1de966840d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention:\n",
    "    def __init__(self, key, config):\n",
    "        assert config.n_embed % config.n_head == 0\n",
    "        qkv_key, proj_key, drop_key = random.split(key, 3)\n",
    "        scale = 1 / jnp.sqrt(config.n_embed)\n",
    "        self.qkv = Linear(qkv_key, config.n_embed, 3 * config.n_embed, bias=True)\n",
    "        self.proj = Linear(proj_key, config.n_embed, config.n_embed, bias=True)\n",
    "        self.n_head = config.n_head\n",
    "        self.dropout = Dropout(drop_key, config.dropout)\n",
    "\n",
    "    def causal_mask_like(self, tensor: DaisyTensor):\n",
    "        T = tensor.shape[-1]\n",
    "        mask = jnp.full((T, T), 0.0)\n",
    "        mask = mask.at[jnp.triu_indices(T, 1)].set(-jnp.inf)\n",
    "        return DaisyTensor(mask[None, None, :, :], requires_grad=tensor.requires_grad)\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        B, T, E = x.shape\n",
    "        qkv_projected = self.qkv(x)\n",
    "        q, k, v = qkv_projected.split(3, axis=-1)\n",
    "        q = q.reshape((B, T, self.n_head, E // self.n_head)).transpose(0, 2, 1, 3)\n",
    "        k = k.reshape((B, T, self.n_head, E // self.n_head)).transpose(0, 2, 1, 3)\n",
    "        v = v.reshape((B, T, self.n_head, E // self.n_head)).transpose(0, 2, 1, 3)\n",
    "\n",
    "        D = q.shape[-1]\n",
    "        scores = q @ k.transpose(0, 1, 3, 2)\n",
    "        scaled_scores = scores / jnp.sqrt(D) \n",
    "        masked_scores = scaled_scores + self.causal_mask_like(scaled_scores)\n",
    "\n",
    "        a = masked_scores.softmax()\n",
    "        z = a @ v\n",
    "        \n",
    "        z = z.transpose(0, 2, 1, 3).reshape((B, T, E))\n",
    "        return self.dropout(self.proj(z), train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "59a94420-ae95-4257-8401-7f38e2974270",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, attn_key = random.split(key)\n",
    "attn = CausalSelfAttention(key, config)\n",
    "x1 = attn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "627ae4ce-d90a-45c7-b485-b1b50945f2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 28, 768)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "69ac6461-b13c-4351-8fd9-50434c1c6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, key, config):\n",
    "        l1_key, l2_key, drop_key = random.split(key, 3)\n",
    "        self.l1 = Linear(l1_key, config.n_embed, 4 * config.n_embed, bias=True)\n",
    "        self.l2 = Linear(l2_key, 4 * config.n_embed, config.n_embed, bias=True)\n",
    "        self.dropout = Dropout(drop_key, config.dropout)\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        return self.dropout(self.l2(self.l1(x).gelu()), train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "86ba6e53-7ce4-42d8-b431-81405bdcb569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self, key, config):\n",
    "        attn_key, mlp_key, drop1_key, drop2_key = random.split(key, 4)\n",
    "        self.attn = CausalSelfAttention(attn_key, config)\n",
    "        self.ln_1 = LayerNorm(config.n_embed)\n",
    "        self.ln_2 = LayerNorm(config.n_embed)\n",
    "        self.mlp = MLP(mlp_key, config)\n",
    "        self.drop1 = Dropout(drop1_key, config.dropout)\n",
    "        self.drop2 = Dropout(drop2_key, config.dropout)\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        x = x + self.drop1(self.attn(self.ln_1(x)), train=train)\n",
    "        x = x + self.drop2(self.mlp(self.ln_2(x)), train=train)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "aa31a195-ce75-46e3-93a9-40ad8f568cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "strings = [\n",
    "    \"The sun is bright.\",\n",
    "    \"Hello world!\",\n",
    "    \"AI is transforming the world.\",\n",
    "    \"Short\"\n",
    "]\n",
    "\n",
    "tok = [tokenizer.encode(s) for s in strings]\n",
    "\n",
    "max_len = max(len(t) for t in tok)\n",
    "padded_tokens = []\n",
    "for token in tok:\n",
    "    padded_tok = jnp.pad(jnp.array(token), pad_width=(0, max_len - len(token)))\n",
    "    padded_tokens.append(padded_tok)\n",
    "    \n",
    "tokarray = jnp.stack(padded_tokens)\n",
    "inputs = tokarray.at[:, :-1].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "dee88e2d-746f-47f9-8d9f-dcc585f6a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(42)\n",
    "key, embed_key = random.split(key)\n",
    "transformer = TransformerBlock(key)\n",
    "embedding = Embed(embed_key, config)\n",
    "x = embedding(inputs)\n",
    "out = transformer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "3386e2cd-592e-4d38-930c-c3c30ca59b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 28, 768)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "4b31a0d1-8ded-4485-8899-5cb54c2f87bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, key):\n",
    "        config = DaisyConfig()\n",
    "        keys = random.split(key, config.n_blocks + 1)\n",
    "        key, embed_key, final_key = random.split(keys[0], 3)\n",
    "        self.embedding = Embed(embed_key, config)\n",
    "        self.blocks = [Transformer(keys[i], config) for i in range(config.n_blocks)]\n",
    "        self.ln_f = LayerNorm(config.n_embed)\n",
    "        self.final = Linear(final_key, config.n_embed, config.vocab_size, bias=True)\n",
    "        self.final.weight = self.embedding.weight.transpose(-1, -2)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        logits = self.final(self.ln_f(x))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3808ad54-20ed-4c6d-b93b-e47e6519d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(42)\n",
    "daisy = Model(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "67c74cce-f63b-4fe3-9712-706c424f7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 28, 4096)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = daisy(inputs)\n",
    "x.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "064a8020-799d-42b8-87c0-d748d206497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as pt\n",
    "freqs = 1.0 / (10000.0 ** (np.arange(0, 128, 2)[: (128 // 2)].astype(np.float32) / 128))\n",
    "t = np.arange(1024, dtype=np.float32)\n",
    "freqs = np.outer(t, freqs)\n",
    "freqs_cis = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961982e4-5fc0-4c52-9fe1-d9207b36be50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test Environment",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
